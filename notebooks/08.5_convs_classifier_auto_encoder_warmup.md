---
jupytext:
  formats: ipynb,md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.14.1
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

```{code-cell} ipython3
from datasets import load_dataset

import torch
from torchvision import transforms
```

```{code-cell} ipython3
hf_ds = load_dataset("beans")
```

```{code-cell} ipython3
hf_ds
```

```{code-cell} ipython3
from torch.utils.data import Dataset
```

```{code-cell} ipython3
class CustomDataset(Dataset):
    def __init__(self, hf_ds):
        self.images = hf_ds['image']
        self.labels = hf_ds['labels']
        
    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx):
        return transforms.PILToTensor()(self.images[idx])/255., self.labels[idx]
    
```

```{code-cell} ipython3
train_ds = CustomDataset(hf_ds['train'])
val_ds = CustomDataset(hf_ds['validation'])
```

```{code-cell} ipython3
from torch.utils.data import DataLoader

train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)
test_dl = DataLoader(val_ds, batch_size=64, shuffle=False)
```

```{code-cell} ipython3
for x,y in train_dl:
    break
```

```{code-cell} ipython3
x.shape, y.shape
```

```{code-cell} ipython3
import torch.nn.functional as F
from torch import nn

class ConvModel(nn.Module):
    def __init__(self):
        super().__init__()
        # in_channels, out_channels, kernel_size, stride=1, padding=0
        self.l1 = nn.Conv2d(3, 32, 3, stride=2, padding=3 // 2)    # ---> 32, 250, 250
        self.l2 = nn.Conv2d(32, 64, 3, stride=2, padding=3 // 2)   # ---> 64, 125, 125

    def forward(self, x):
        x = self.l1(x)
        x = F.relu(x)
        x = self.l2(x)
        x = F.relu(x)
        x = nn.Flatten()(x)
        x = F.softmax(nn.Linear(x.shape[-1],3)(x),dim=1) # classification layer
        return x
```

```{code-cell} ipython3
self = ConvModel()
self(x).shape
```

```{code-cell} ipython3
model = ConvModel()
from torch import optim
opt = optim.SGD(model.parameters(), lr=0.01)
```

```{code-cell} ipython3

```

```{code-cell} ipython3
for epoch in range(5):
    model.train()
    for x, y in train_dl:
        pred = model(x)
        loss = F.cross_entropy(pred, y)
        loss.backward()
        opt.step()
        opt.zero_grad()
        print(loss)    
```

Great tutorial by Jeremy [here](https://pytorch.org/tutorials/beginner/nn_tutorial.html#neural-net-from-scratch-no-torch-nn)

+++

lol, what am I doing wrong?

+++

Then try autoencoder here.

+++

## Autoencoder

```{code-cell} ipython3

```

```{code-cell} ipython3

```

```{code-cell} ipython3

```

```{code-cell} ipython3

```
